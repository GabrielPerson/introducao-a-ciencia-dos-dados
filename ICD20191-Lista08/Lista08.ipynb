{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "796114292f40d93792b787b19fbed7ee",
     "grade": false,
     "grade_id": "cellc-a00",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Lista 08 - Comparando Regressões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c77a6c3fedbe648e6e209ba6323f711e",
     "grade": false,
     "grade_id": "cell-acd6c643a4ce1477",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Exercício 01:\n",
    "\n",
    "Analise o desempenho do kNN e de uma Regressão Linear Regularizada para **pelo menos um** dos conjuntos de dados disponível na [seção de regressão linear múltipla](http://college.cengage.com/mathematics/brase/understandable_statistics/7e/students/datasets/mlr/frames/frame.html) da página do *Livro Understandable Statistics* de Charles Brase e Corrinne Brase. Para o conjunto de dados que escolheu, execute a regressão linear múltipla para explicar o fator $X1$ dos dados ([ver descrição de um dos conjuntos](http://college.cengage.com/mathematics/brase/understandable_statistics/7e/students/datasets/mlr/frames/frame.html)) a partir dos outros fatores. \n",
    "\n",
    "Para a questão, faça as seguintes tarefas:\n",
    "\n",
    "* Realize treino, validação e teste\n",
    "* Compare as métricas no teste\n",
    "* Diferente da lista anterior, reporte o erro quadrado médio no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Um fator importante é que o SKLearn não cria conjuntos de validação para você. Você tem algumas abordagens,\n",
    "# uma é realizar um novo split no treino. Outra é fazer uso de classificadores com CV no fim.\n",
    "# Tipo LogisticRegressionCV (ver na API). Por fim, você pode fazer uso da classe GridSearchCV.\n",
    "# Leia a documentação da mesma.\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** No CODEPAGE record, no encoding_override: will use 'ascii'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.283</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.276</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.281</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.328</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.290</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.296</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.248</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.228</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.305</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.254</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.269</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.300</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.307</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.214</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.329</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       X1     X2     X3     X4     X5     X6\n",
       "0   0.283  0.144  0.049  0.012  0.013  0.086\n",
       "1   0.276  0.125  0.039  0.013  0.002  0.062\n",
       "2   0.281  0.141  0.045  0.021  0.013  0.074\n",
       "3   0.328  0.189  0.043  0.001  0.030  0.032\n",
       "4   0.290  0.161  0.044  0.011  0.070  0.076\n",
       "5   0.296  0.186  0.047  0.018  0.050  0.007\n",
       "6   0.248  0.106  0.036  0.008  0.012  0.095\n",
       "7   0.228  0.117  0.030  0.006  0.003  0.145\n",
       "8   0.305  0.174  0.050  0.008  0.061  0.112\n",
       "9   0.254  0.094  0.041  0.005  0.014  0.124\n",
       "10  0.269  0.147  0.047  0.012  0.009  0.111\n",
       "11  0.300  0.141  0.058  0.010  0.011  0.070\n",
       "12  0.307  0.135  0.041  0.009  0.005  0.065\n",
       "13  0.214  0.100  0.037  0.003  0.004  0.138\n",
       "14  0.329  0.189  0.058  0.014  0.011  0.032"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using baseball Dataset\n",
    "\n",
    "df = pd.read_excel('mlr08.xls',sep=',')\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c4c170d5f5a66e6cffe2a8da92fb9285",
     "grade": true,
     "grade_id": "cell-1b46a0ab690a7b8c",
     "locked": false,
     "points": 4,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Linear Regression (Mean Squared Error): 0.0003153670479277026\n",
      "MSE KNN (Mean Squared Error): 0.00033648214285714287\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "#Linear Reg. train-test-valid\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('X1',axis=1), df['X1'], test_size=0.30, random_state=101)\n",
    "\n",
    "X_train, X_val, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=101)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_new_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test = (X_test - X_train.mean()) / X_train.std(ddof=1)\n",
    "X_test_new = scaler.transform(X_test)\n",
    "\n",
    "#KNN train-test-valid\n",
    "X_train_knn, X_test_knn, y_train_knn, y_test_knn = train_test_split(df.drop('X1',axis=1),df['X1'],test_size=0.30, random_state=101)\n",
    "\n",
    "X_train_knn, X_valid_knn, y_train_knn, y_valid_knn = train_test_split(X_train_knn, y_train_knn, test_size=0.3, random_state=101)\n",
    "\n",
    "linmodel = LinearRegression()\n",
    "linmodel.fit(X_new_train,y_train)\n",
    "pred_lin = linmodel.predict(X_test)\n",
    "\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=2)\n",
    "knn.fit(X_train_knn,y_train_knn)\n",
    "pred_knn = knn.predict(X_test_knn)\n",
    "\n",
    "\n",
    "print('MSE Linear Regression (Mean Squared Error):', mean_squared_error(y_test, pred_lin))\n",
    "\n",
    "print('MSE KNN (Mean Squared Error):', mean_squared_error(y_test_knn,pred_knn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c5c0a788bafbd1227adf600b857ee636",
     "grade": false,
     "grade_id": "cell-b8fab7f24e1b2a35",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Explique e discuta sobre os resultados encontrados no campo abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "27383ddc0e3db055b7bbfb577b77eca6",
     "grade": true,
     "grade_id": "cell-713eb691ead1e6c1",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
